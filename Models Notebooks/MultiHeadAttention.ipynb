{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"MultiHeadAttention.ipynb","provenance":[{"file_id":"1mcWeCfcBO_BeueieRtmJ9ooE6KrfVSzs","timestamp":1618740259933},{"file_id":"1-eLaA2mKCYl65XmvjMF-fdoP93wSEZVv","timestamp":1618719269574}],"collapsed_sections":["4z8By_tiEGEN","zD3JettqJcSe","s_rZ0xOYQTde","yi1Uyx6qjZUH","ucAyxONDpc_G","4IHez2DI1E93","UwrzEJEIBgVw","JQhL8hZdQfux","IeGffW0VcmFJ","Whh2XoGMhHlP"],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"eU6LCqMTEfZC"},"source":["# Packages"]},{"cell_type":"code","metadata":{"id":"rCUYzfl6AtcW"},"source":["!pip install hazm"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"psdX3GaqEg4i"},"source":["import tensorflow as tf\n","\n","import matplotlib.pyplot as plt\n","import matplotlib.ticker as ticker\n","from sklearn.model_selection import train_test_split\n","\n","import string\n","import unicodedata\n","import re\n","import numpy as np\n","import os\n","import io\n","import time\n","import pickle\n","import pandas as pd\n","import hazm\n","import gc\n","pd.set_option('display.max_rows', 50)\n","pd.set_option('display.max_colwidth', None)\n","from termcolor import colored\n","from itertools import chain\n","#from transformers import BertTokenizer, BertModel\n","who_am_i = 'Mitra'"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IZR2Rl7iE0jJ"},"source":["# Data"]},{"cell_type":"code","metadata":{"id":"1MSiyiIyEiaT"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wRIXGiqfE2tj"},"source":["all_data = pd.read_csv('.../ProsPoemParallelDataset_augmented.csv')\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QHSlt1lSE-pZ"},"source":["all_data.head(2)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"65-Ut7KiFC4W"},"source":["# PreProcessing + Creating Inputs"]},{"cell_type":"code","metadata":{"id":"PSooe2R4E-nR"},"source":["normalizer = hazm.Normalizer(persian_numbers=False)\n","\n","def process_sents(text):\n","    \n","    # separate dot or / from text with\n","    # one white space\n","    text = normalizer.normalize(text)\n","\n","    text = re.sub(r'([\\/\\.])', r' \\1', text)\n","\n","    # substitute / with sep between mesras\n","    text = re.sub(r' *\\/ *', ' <sep> ', text)\n","    \n","    # substitute any white space with one space\n","    text = re.sub(r'\\s+', ' ', text)\n","    \n","    # add start and end tokens\n","    text = '<start> ' + text + ' <end>'\n","    \n","    return text\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZO8yDRsQE-k4"},"source":["def tokenize(lang):\n","    # use keras defualt tokenizer\n","    lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(\n","        filters=''\n","    )\n","    # fit on the vocabulary used in text\n","    lang_tokenizer.fit_on_texts(lang)\n","\n","    # convert to ids\n","    tensor = lang_tokenizer.texts_to_sequences(lang)\n","    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,\n","                                                           padding = 'post')\n","    \n","    # add sep to the tokenizer\n","    #idx_sep = len(lang_tokenizer.index_word.keys())+1#[-1]\n","\n","    #lang_tokenizer.word_index['<sep>'] = idx_sep\n","    #lang_tokenizer.index_word[idx_sep] = '<sep>'\n","\n","\n","    return tensor, lang_tokenizer"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7eSqfbU1E-io"},"source":["def create_load_dataset(df):\n","\n","    input_lang = df.loc[:, 'text'].values.tolist()\n","    target_lang = df.loc[:, 'poetry'].values.tolist()\n","\n","    # preprocess each sentence\n","    input_lang = [process_sents(text) for text in input_lang]\n","    target_lang = [process_sents(text) for text in target_lang]\n","\n","    # create a tensor and tokenizer for each language\n","    input_tensor, input_lang_tokenizer = tokenize(input_lang)\n","    target_tensor, target_lang_tokenizer = tokenize(target_lang)\n","\n","    return input_tensor, target_tensor, input_lang_tokenizer, target_lang_tokenizer"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SzSgn3tbE-go"},"source":["input_tensor, target_tensor,\\\n","input_lang_tokenizer, target_lang_tokenizer = create_load_dataset(all_data)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Zgt4bv8UE-eo"},"source":["max_len_input = input_tensor.shape[1]\n","max_len_target = target_tensor.shape[1]\n","\n","print('longest sequence and the length of texts: ',\n","      colored(max_len_input, 'blue'))\n","print('longest sequence and the length of poetries: ',\n","      colored(max_len_target, 'blue'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4tBClWaG82yq"},"source":["print('Start token:',  target_lang_tokenizer.word_index['<start>'])\n","print('End token:',  target_lang_tokenizer.word_index['<end>'])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IML5iqJUU1Gl"},"source":["# Vocabulary"]},{"cell_type":"code","metadata":{"id":"CAUTXOwBxfap"},"source":["target_lang_tokenizer.word_index['<sep>']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"H7XcFv5exqTW"},"source":["#target_lang_tokenizer.index_word[10434]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OVXcF-PcxvKG"},"source":["#target_lang_tokenizer.index_word[3]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z5eSfnvFw_9G"},"source":["#target_lang_tokenizer.index_word"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VakgJrqdT3MG"},"source":["# lenght of constructed vocabularies:\n","# 1 for padding\n","vocab_len_i = len(input_lang_tokenizer.index_word) + 1\n","print(\"Plain text vocab has\", colored(f\"{vocab_len_i:,}\", 'green'), \"unique words.\")\n","\n","vocab_len_t = len(target_lang_tokenizer.index_word) + 1\n","print(f\"Poetry vocab has\", colored(f\"{vocab_len_t:,}\", 'green'), \"unique words.\")\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FDTkYmAZU4Ek"},"source":["def convert(text, poetry):\n","\n","\n","    print(colored('Text:', 'green'))\n","    for i in text:\n","        if i!=0:\n","            print(\"%d -----> %s\"%(i, input_lang_tokenizer.index_word[i]))\n","        \n","    print(colored('\\nPoetry:', 'green'))\n","    for i in poetry:\n","        if i!=0:\n","            print(\"%d -----> %s\"%(i, target_lang_tokenizer.index_word[i]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dyfdE42aU379"},"source":["print(colored('Text: ', 'blue'), all_data.loc[5, 'text'])\n","print(colored('Poetry: ', 'blue'), all_data.loc[5, 'poetry'])\n","convert(input_tensor[5], target_tensor[5])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8CMt3PJvHERK"},"source":["# Create the Input"]},{"cell_type":"code","metadata":{"id":"sYAl7F4ozDJ2"},"source":["val_indices = pd.read_pickle('.../validation_indices_le')\n","train_indices = pd.read_pickle('.../train_indices_.pickle')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wlgmw-19zNvz"},"source":["all_data.loc[val_indices]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fgejklC-WnRZ"},"source":["input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val =\\\n","input_tensor[train_indices], input_tensor[val_indices],  target_tensor[train_indices], target_tensor[val_indices]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WshBhSIGHLAI"},"source":["\"\"\"\n","# segmenting the dataset\n","input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = \\\n","train_test_split(pd.Series(input_tensor.tolist()),\n","                 pd.Series(target_tensor.tolist()),\n","                 test_size=0.06, shuffle = True)\n","\"\"\"\n","\n","print('Length of train and val:', \n","      colored(f\"{len(input_tensor_train), len(input_tensor_val)}\", 'blue'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vV6H0ckR0k3l"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SvXZbDPyY9Te"},"source":["\"\"\"\n","with open('.../validation_indices_.pickle', 'wb') as f:\n","    pickle.dump(input_tensor_val.index, f)\n","\n","with open('.../train_indices_.pickle', 'wb') as f:\n","    pickle.dump(train_.index, f)\n","\"\"\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"582Moj4YE-cj"},"source":["# defining the main parameters of the model\n","# and the inputs\n","\n","len_data = len(input_tensor_train)\n","batch_s = 128\n","steps_per_epoch = len_data // batch_s\n","embedding_dim = 256\n","units = 1024"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"afjVR1jgYha6"},"source":["np.array(input_tensor_train.tolist(), dtype='int32')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Gh-EID43E-aJ"},"source":["# create the dataset and shuffle all\n","len_data_train = len(input_tensor_train)\n","len_data_test = len(target_tensor_val)\n","\n","# creat the datasets and put them in batches\n","\n","train_batches = tf.data.Dataset.from_tensor_slices((\n","    np.array(input_tensor_train.tolist(), dtype='int32'),\n","     np.array(target_tensor_train.tolist(), dtype='int32')\n",")).shuffle(len_data_train).batch(batch_s, drop_remainder=True)\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4z8By_tiEGEN"},"source":["# Positional Encoding\n"]},{"cell_type":"code","metadata":{"id":"1FAqkMPcD9d0"},"source":["def get_angles(pos, i, d_model):\n","    angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n","    return pos * angle_rates"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"F4EdFe9ED9bF"},"source":["def positional_encoding(position, d_model):\n","\n","    angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n","                            np.arange(d_model)[np.newaxis, :],\n","                            d_model)\n","    \n","    # sine to even indices\n","    # start with 0 and jump every 1 indices\n","    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n","\n","    # cosine to odd indices\n","    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n","\n","    pos_encoding = angle_rads[np.newaxis, ...]\n","\n","    return tf.cast(pos_encoding, dtype=tf.float32)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"g2FsBBt05iKA"},"source":["list(range(10)[0::2])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6JStu8pPD9YX"},"source":["n_position = 1024\n","d_model = 512\n","pos_encoding = positional_encoding(n_position, d_model)\n","print(pos_encoding.shape)\n","pos_encoding = pos_encoding[0]\n","\n","# ----------------irrelevant-----------\n","# Juggle the dimensions for the plot\n","pos_encoding = tf.reshape(pos_encoding, (n_position, d_model//2, 2))\n","pos_encoding = tf.transpose(pos_encoding, (2, 1, 0))\n","pos_encoding = tf.reshape(pos_encoding, (d_model, n_position))\n","\n","plt.pcolormesh(pos_encoding, cmap='RdBu')\n","plt.ylabel('Depth')\n","plt.xlabel('Position')\n","plt.colorbar()\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zD3JettqJcSe"},"source":["# Padding"]},{"cell_type":"code","metadata":{"id":"szb_sJdnD9V0"},"source":["def create_padding_mask(seq):\n","    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n","\n","    # add extra dimention to add the padding\n","    return seq[:, tf.newaxis, tf.newaxis, :]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RlSNOgP56a6J"},"source":["x = tf.constant([[7, 6, 0, 0, 1], \n","                 [1, 2, 3, 0, 0], \n","                 [0, 0, 0, 4, 5]])\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"U7x6wuAQ6h7I"},"source":["tf.cast(tf.math.equal(x, 0), tf.float32)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qqsUFP3-D9TW"},"source":["create_padding_mask(x)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LfLHLvcDD9Qv"},"source":["def create_look_ahead_mask(size):\n","    # put 1 where the sequence has to be masked\n","    # in here the lower triangular part will be zero. \n","    # then we say 1- this which will be the upper without\n","    # the diagonal axis\n","    # 1 = mask\n","    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0 )\n","    return mask # (seq_len, seq_len)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3F-T7712D9N9"},"source":["x = tf.random.uniform((1,3))\n","x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qiw5ynaNPaLd"},"source":["x.shape[1]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jPkBYDF9D9Ic"},"source":["create_look_ahead_mask(x.shape[1])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"s_rZ0xOYQTde"},"source":["# Scaled Dot Product"]},{"cell_type":"code","metadata":{"id":"MfTKwL9PPtV8"},"source":["def scaled_dot_product_attention(q, k, v, mask):\n","\n","    # multiplying q and k first and transposing k\n","    matmul_qk = tf.matmul(q, k, transpose_b=True)\n","\n","    # we scale it using the depth of model\n","    d_k = tf.cast(tf.shape(k)[-1], tf.float32)\n","    scaled_attention_logits = matmul_qk / tf.math.sqrt(d_k)\n","\n","    # adding mask to the scaled attention\n","    # by multiplying the mask(1) with a very small number\n","    if mask is not None:\n","        scaled_attention_logits += (mask * -1e9)\n","\n","    # softmax on the last dimention which makes the sequence length\n","    # of k sequence length be between 0 and 1\n","    # meaning: which one in the input is more important\n","    attention_weights = tf.nn.softmax(scaled_attention_logits, \n","                                      axis=-1)\n","    \n","    output = tf.matmul(attention_weights, v)\n","    # (..., seq_len_q, depth_v)\n","\n","    return output, attention_weights"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WbYHhgrkPtJk"},"source":["def print_att(q, k, v):\n","    output, att_weights = scaled_dot_product_attention(\n","        q, k, v, None\n","    )\n","    print('Attention weights: ', att_weights)\n","    print('Output is:', output)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ct8ozfl2PtHV"},"source":["np.set_printoptions(suppress=True)\n","\n","k = tf.constant([[10, 0, 0],\n","                [0, 10, 0],\n","                [0, 0, 10],\n","                [0, 0, 10]], dtype=tf.float32)  # (4, 3)\n","\n","\n","v = tf.constant([[1, 0],\n","                [10, 0],\n","                [100, 5],\n","                [1000, 6]], dtype=tf.float32)  # (4, 2)\n","\n","q = tf.constant([[0, 10, 0]], dtype=tf.float32)  # (1, 3)\n","print_att(q, k, v)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"at2oXnEiPtFM"},"source":["# This query aligns with a repeated key (third and fourth),\n","# so all associated values get averaged.\n","temp_q = tf.constant([[0, 0, 10]], dtype=tf.float32)  # (1, 3)\n","print_att(temp_q, k, v)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aHEKpx1pG9vU"},"source":["# Multihead"]},{"cell_type":"code","metadata":{"id":"ON3uBuqkY6gk"},"source":["class MultiHeadAttention(tf.keras.layers.Layer):\n","    def __init__(self, d_model, num_heads):\n","\n","        # d_model = embedding dimension\n","        super(MultiHeadAttention, self).__init__()\n","        self.num_heads = num_heads\n","        self.d_model = d_model\n","\n","\n","        assert d_model % self.num_heads == 0\n","\n","        self.depth = d_model // self.num_heads\n","\n","        self.wq = tf.keras.layers.Dense(d_model)\n","        self.wk = tf.keras.layers.Dense(d_model)\n","        self.wv = tf.keras.layers.Dense(d_model)\n","\n","        self.dense = tf.keras.layers.Dense(d_model)\n","\n","    def split_heads(self, x, batch_size):\n","        # we're separating the last dimention into\n","        # different heads with one depth\n","        # Transpose: (batch_size, num_heads, sequence_length, depth)\n","\n","        x = tf.reshape(x, (batch_size,\n","                           -1,\n","                           self.num_heads, \n","                           self.depth))\n","        return tf.transpose(x, perm=[0, 2, 1, 3])\n","\n","    def call(self, v, k, q, mask):\n","\n","        batch_size = tf.shape(q)[0]\n","\n","        # shapes: (batch_size, seq_len, d_model)\n","        q = self.wq(q)\n","        k = self.wk(k)\n","        v = self.wv(v)\n","\n","        # shapes: (batch_size, num_heads, seq_len_q, depth)\n","        q = self.split_heads(q, batch_size)\n","        k = self.split_heads(k, batch_size)\n","        v = self.split_heads(v, batch_size)\n","\n","        scaled_attention, attention_weights = scaled_dot_product_attention(\n","    q, k, v, mask)\n","        \n","        # transpose and bring it to the normal mode\n","        scaled_attention = tf.transpose(scaled_attention,\n","                                        perm=[0, 2, 1, 3])\n","        concat_attention = tf.reshape(scaled_attention,\n","                                        (batch_size, -1, self.d_model))\n","        # shape : (batch_s, seq_len_q, d_model)\n","        # seq_len_q should be input_seq_len!!!! -----------------\n","        output = self.dense(concat_attention) \n","\n","        return output, attention_weights"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ajBVm8LpY6dF"},"source":["temp_mha = MultiHeadAttention(d_model=512, num_heads=8)\n","\n","y = tf.random.uniform((1, 60, 512)) # (batch_size, encoder_sequence, d_model)\n","out, attn = temp_mha(y, k=y, q=y, mask=None)\n","print('output shape: ', out.shape)\n","print('attention weights shape: ', attn.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RHfHNH0kY6aF"},"source":["def point_wise_feed_forward_network(d_model, d_ff):\n","    # 2 fully connected\n","    # one ReLU in between\n","    return tf.keras.Sequential([\n","        # shape: (batch_size, seq_len, d_ff)\n","        tf.keras.layers.Dense(d_ff, activation='relu'), \n","        # shape: (batch_size, seq_len, d_model)\n","        tf.keras.layers.Dense(d_model)\n","    ])\n","    "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y4huGsVTY6Xs"},"source":["# you may want to change this---------------------------\n","# 2048 to 1024\n","sample_ffn = point_wise_feed_forward_network(512, 2048)\n","# (batch_size, seq_len, d_model)\n","sample_ffn(tf.random.uniform((64, 50, 512))).shape"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yi1Uyx6qjZUH"},"source":["# Encoder Layer"]},{"cell_type":"code","metadata":{"id":"jV-d_vapY6U_"},"source":["# pass through n encoder layers\n","# decoder attends on its own and the encoders output\n","\n","class EncoderLayer(tf.keras.layers.Layer):\n","    def __init__(self, d_model, num_heads,\n","                 d_ff, rate=0.1):\n","        super(EncoderLayer, self).__init__()\n","\n","        self.mha = MultiHeadAttention(d_model, num_heads)\n","        self.ff_net = point_wise_feed_forward_network(d_model, d_ff)\n","\n","        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n","        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n","\n","        self.dropout1 = tf.keras.layers.Dropout(rate)\n","        self.dropout2 = tf.keras.layers.Dropout(rate)\n","        \n","    def call(self, x, training, mask):\n","        \n","        # shape : (batch_size, input_seq_len, d_model)\n","        attn_output, _ = self.mha(x, x, x, mask)\n","        attn_output = self.dropout1(attn_output, training=training)\n","\n","        # shape : (batch_size, input_seq_len, d_model)\n","        out1 = self.layernorm1(x + attn_output)\n","\n","        # ---------------------------------\n","\n","        # shape : (batch_size, input_seq_len, d_model)\n","        ff_net_output = self.ff_net(out1)\n","        ff_net_output = self.dropout2(ff_net_output, training=training)\n","        \n","        # shape : (batch_size, input_seq_len, d_model)\n","        out2 = self.layernorm2(out1 + ff_net_output)\n","\n","        return out2"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OSH3BThBY6Sc"},"source":["sample_encoder_layer = EncoderLayer(d_model=512,\n","                                    num_heads=8,\n","                                    d_ff=2048)\n","\n","sample_encoder_layer_o = sample_encoder_layer(\n","    tf.random.uniform((64, 43, 512)),\n","    training = False,\n","    mask = None\n",")\n","\n","# shape : (batch_size, input_seq_len, d_model)\n","print('output of encoder layer: shape: ', sample_encoder_layer_o.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ucAyxONDpc_G"},"source":["# Decoder Layer"]},{"cell_type":"code","metadata":{"id":"QJu1qhFGY6Pn"},"source":["class DecoderLayer(tf.keras.layers.Layer):\n","\n","    def __init__(self, d_model, num_heads, \n","                 d_ff, rate=0.1):\n","        super(DecoderLayer, self).__init__()\n","\n","        self.mha_1 = MultiHeadAttention(d_model, num_heads)\n","        self.mha_2 = MultiHeadAttention(d_model, num_heads)\n","\n","        self.ff_net = point_wise_feed_forward_network(d_model, d_ff)\n","\n","        self.layernorm_1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n","        self.layernorm_2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n","        self.layernorm_3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n","\n","\n","        self.dropout_1 = tf.keras.layers.Dropout(rate)\n","        self.dropout_2 = tf.keras.layers.Dropout(rate)\n","        self.dropout_3 = tf.keras.layers.Dropout(rate)\n","        \n","    def call(self, x, encoder_output, training,\n","            look_ahead_mask, padding_mask):\n","        # encoder_output shape:\n","        # (batch_s, input_seq_len, d_model)\n","\n","        # Self Attention ------------------------------\n","\n","        # attn1 shape: (batch_size, target_seq_len, d_model)\n","        attention_1, attention_w_block_1 = self.mha_1(x, x, x, look_ahead_mask)\n","        \n","        attention_1 = self.dropout_1(attention_1, training=training)\n","        # residual\n","        output_1 = self.layernorm_1(attention_1 + x)\n","\n","\n","        # Causal Attention----------------------------\n","\n","        # attn2 shape: (batch_size, target_seq_len, d_model)\n","        attention_2, attention_w_blocks_2 = self.mha_2(\n","            encoder_output, encoder_output, output_1, padding_mask\n","        )\n","        attention_2 = self.dropout_2(attention_2, training=training)\n","\n","        output_2 = self.layernorm_2(attention_2 + output_1)\n","\n","        # Feed Forward Network-----------------------------\n","\n","        # shape:  (batch_size, target_seq_len, d_model)\n","        ff_output = self.ff_net(output_2)     \n","        ff_output = self.dropout_3(ff_output, training=training)\n","\n","        # shape (batch_size, target_seq_len, d_model)\n","        output_3 = self.layernorm_3(ff_output + output_2)\n","        \n","        return output_3, attention_w_block_1, attention_w_blocks_2\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pBkupFcfY6M9"},"source":["sample_decoder_layer = DecoderLayer(d_model=512,\n","                                    num_heads=8, \n","                                    d_ff=2048)\n","\n","sample_decoder_layer_output, _, _ = sample_decoder_layer(\n","    tf.random.uniform((64, 50, 512)),\n","    sample_encoder_layer_o,\n","    training=False,\n","    look_ahead_mask=None,\n","    padding_mask=None\n",")\n","\n"," # (batch_size, target_seq_len, d_model)\n","print('Output shape of our decoder: ', sample_decoder_layer_output.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4IHez2DI1E93"},"source":["# Encoder"]},{"cell_type":"code","metadata":{"id":"P9RcOqiGY6Kl"},"source":["# input embeddings\n","# positional encoding\n","# add them up\n","# n encoder layers"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TXamiq9GY6EM"},"source":["class Encoder(tf.keras.layers.Layer):\n","    def __init__(self, num_layers, d_model, num_heads,\n","                 d_ff, input_vocab_size,\n","                 maximum_position_encoding, \n","                 rate = 0.1):\n","    \n","        super(Encoder, self).__init__()\n","\n","        self.d_model = d_model\n","        self.num_layers = num_layers\n","\n","        self.embeddings = tf.keras.layers.Embedding(input_vocab_size,\n","                                                    d_model)\n","        self.pos_encoding = positional_encoding(maximum_position_encoding,\n","                                                self.d_model)\n","        self.encoder_layers = [\n","            EncoderLayer(d_model, num_heads, d_ff, rate) for _ in range(num_layers)\n","            ]\n","\n","\n","        self.dropout = tf.keras.layers.Dropout(rate)\n","    def call(self, x, training, mask):\n","\n","        seq_len = tf.shape(x)[1]\n","\n","        # shape: (batch_s, input_seq_len, d_model)\n","        x = self.embeddings(x) \n","        # making it float and them taking the square root\n","        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n","        x += self.pos_encoding[:, :seq_len, :]\n","\n","        x = self.dropout(x, training=training)\n","\n","        for i in range(self.num_layers):\n","            # (batch_size, input_seq_len, d_model)\n","            x = self.encoder_layers[i](x, training, mask)\n","\n","        return x\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"afp2cwb_Y6Bl"},"source":["sample_encoder = Encoder(num_layers=2, d_model=512, \n","                         num_heads=8, d_ff=2048,\n","                         input_vocab_size=8500,\n","                         maximum_position_encoding=10000)\n","\n","temp_input = tf.random.uniform((64, 62),\n","                               dtype=tf.int64,\n","                               minval=0, maxval=200\n","                               )\n","sample_encoder_output = sample_encoder(temp_input,\n","                                       training=False,\n","                                       mask=None)\n","print('Sample encoder output shape: ', sample_encoder_output.shape)\n","# (batch_s, input_seq_len, d_model)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UwrzEJEIBgVw"},"source":["# Decoder"]},{"cell_type":"code","metadata":{"id":"cDmHyY_0D8_M"},"source":["# output embedding\n","# positional encoding\n","# add them up\n","# n * decoder layers"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VfXxNBt-Bh24"},"source":["class Decoder(tf.keras.layers.Layer):\n","    def __init__(self, num_layers, d_model,\n","                 num_heads, d_ff, target_vocab_size,\n","                 maximum_position_encoding,\n","                 rate=0.1):\n","        super(Decoder, self).__init__()\n","        self.d_model = d_model\n","        self.num_layers = num_layers\n","\n","        self.embeddings = tf.keras.layers.Embedding(target_vocab_size, d_model)\n","        self.pos_encoding = positional_encoding(maximum_position_encoding,\n","                                                d_model)\n","        \n","        self.decoder_layers = [\n","            DecoderLayer(d_model, num_heads, d_ff, rate) for _ in range(num_layers)\n","            ]\n","\n","        self.dropout = tf.keras.layers.Dropout(rate)\n","\n","    def call(self, x, encoder_output, training, \n","             look_ahead_mask, padding_mask):\n","        \n","        seq_len = tf.shape(x)[1]\n","\n","        attention_weights = {}\n","\n","        # (batch_size, targe_seq_len, d_model)\n","        x = self.embeddings(x)\n","        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n","        x += self.pos_encoding[:, :seq_len, :]\n","\n","\n","        x = self.dropout(x, training=training)\n","\n","        for i in range(self.num_layers):\n","            x, block_1, block_2 = self.decoder_layers[i](x, \n","                                                        encoder_output,\n","                                                        training,\n","                                                        look_ahead_mask,\n","                                                        padding_mask)\n","            attention_weights[f'decoder_layer{i+1}_block_1'] = block_1\n","            attention_weights[f'decoder_layer{i+1}_block_2'] = block_2\n","\n","        # shape x : (batch_size, target_seq_len, d_model)\n","        return x, attention_weights"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-1g-ICMFBhzZ"},"source":["sample_decoder = Decoder(num_layers=2,\n","                         d_model=512,\n","                         num_heads=8,\n","                         d_ff=2048,\n","                         target_vocab_size=80000,\n","                         maximum_position_encoding=5000)\n","\n","temp_input = tf.random.uniform((64, 26),\n","                               dtype=tf.int64,\n","                               minval=0, maxval=200)\n","\n","output, att = sample_decoder(temp_input,\n","                             encoder_output=sample_encoder_output,\n","                             training=False,\n","                             look_ahead_mask=None,\n","                             padding_mask=None)\n","\n","print('Shape of the Decoder output: ', output.shape)\n","\n","print('Shape of the attention output: ', att['decoder_layer2_block_2'].shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JQhL8hZdQfux"},"source":["# Transformer"]},{"cell_type":"code","metadata":{"id":"tpvUZH6ZBhyC"},"source":["class Transformer(tf.keras.Model):\n","    def __init__(self, num_layers,\n","                 d_model, num_heads,\n","                 d_ff, input_vocab_size, \n","                 target_vocab_size,\n","                 pe_input, pe_target,\n","                 rate=0.1):\n","        super(Transformer, self).__init__()\n","\n","        self.tokenizer = Encoder(num_layers, d_model, \n","                                 num_heads, d_ff, \n","                                 input_vocab_size, \n","                                 pe_input,\n","                                 rate)\n","        self.decoder = Decoder(num_layers, d_model, num_heads,\n","                               d_ff, target_vocab_size, pe_target,\n","                               rate)\n","        # softmax?\n","        self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n","\n","    def call(self, input_, target, training,\n","             encoder_padding_mask,\n","             look_ahead_mask, decoder_padding_mask):\n","        \n","        # shape: (batck_s, inp_seq_len, d_model)\n","        encoder_output = self.tokenizer(input_, training,\n","                                        encoder_padding_mask)\n","        \n","        decoder_output, attention_weights = self.decoder(\n","            target, encoder_output, training, look_ahead_mask,\n","            decoder_padding_mask\n","        )\n","        \n","        final_output = self.final_layer(decoder_output)\n","\n","        # shape output: (batch_size, seq_len, vocab_size)\n","        return final_output, attention_weights"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-mj1i2BIBhqB"},"source":["sample_transformer = Transformer(\n","    num_layers=2, d_model=512, num_heads=8,\n","    d_ff=2048, input_vocab_size=8500,\n","     target_vocab_size=8000,\n","    pe_input=1000, pe_target=6000\n",")\n","\n","temp_input = tf.random.uniform((64, 38), dtype=tf.int64, minval=0, maxval=200)\n","temp_target = tf.random.uniform((64, 36), dtype=tf.int64, minval=0, maxval=200)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"esYsjcA8BhnJ"},"source":["fn_out, _ = sample_transformer(temp_input,\n","                               temp_target, \n","                               training=False,\n","                               encoder_padding_mask=None,\n","                               look_ahead_mask=None,\n","                               decoder_padding_mask=None)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AB5-AU4uD88c"},"source":["fn_out.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6CD1-DF7E9_H"},"source":["class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n","    def __init__(self, d_model, warmup_steps=4000):\n","\n","        super(CustomSchedule, self).__init__()\n","\n","        self.d_model = d_model\n","        self.d_model = tf.cast(self.d_model, tf.float32)\n","\n","        self.warmup_steps = warmup_steps\n","\n","    def __call__(self, step):\n","        arg_1 = tf.math.rsqrt(step)\n","        arg_2 = step * (self.warmup_steps ** -1.5)\n","\n","        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg_1, arg_2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"r9FLehCqWAZc"},"source":["learning_rate = CustomSchedule(d_model)\n","\n","optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98,\n","                                     epsilon=1e-9)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Lo5gUwqVWIR-"},"source":["temp_learning_rate_schedule = CustomSchedule(d_model)\n","\n","plt.plot(temp_learning_rate_schedule(tf.range(40000, dtype=tf.float32)))\n","plt.ylabel(\"Learning Rate\")\n","plt.xlabel(\"Train Step\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"z_4mWaqfWIPw"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"g_-Aw_2PRMc2"},"source":["# Loss"]},{"cell_type":"code","metadata":{"id":"uDN4rVekWINk"},"source":["loss_obj = tf.keras.losses.SparseCategoricalCrossentropy(\n","    from_logits=True,\n","    reduction='none'\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"M2eAwtdBWILa"},"source":["def loss_function(real, pred):\n","\n","    # apply a mask first\n","    mask = tf.math.logical_not(tf.math.equal(real, 0))\n","    loss_ = loss_obj(real, pred)\n","\n","    mask = tf.cast(mask, dtype=loss_.dtype)\n","    loss_ *= mask\n","\n","    return tf.reduce_sum(loss_)/tf.reduce_sum(mask)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ItXPeMc2WIHi"},"source":["def accuracy_function(real, pred):\n","\n","    #print('accuracy fun 1')\n","    accuracies = tf.equal(real, tf.argmax(pred,\n","                                          axis=2,\n","                                          output_type=tf.int32))\n","    #print('into accuracy function')\n","    mask = tf.math.logical_not(tf.math.equal(real, 0))\n","    accuracies = tf.math.logical_and(mask, accuracies)\n","\n","    accuracies = tf.cast(accuracies, dtype=tf.float32)\n","    #print('first casting')\n","    mask = tf.cast(mask, dtype=tf.float32)\n","    #print('second casting')\n","    return tf.reduce_sum(accuracies)/tf.reduce_sum(mask)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2aVaGRHDWIFa"},"source":["\n","train_loss = tf.keras.metrics.Mean(name='train_loss')\n","train_accuracy = tf.keras.metrics.Mean(name='train_accuracy')\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lJXcCf-5ju8T"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-9lycJo1TRG7"},"source":["num_layers = 4\n","d_model = 128\n","d_ff = 512\n","num_heads = 8\n","dropout_rate = 0.1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IVK8q0ZATT3R"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eUR6nye2WIDK"},"source":["transformer = Transformer(\n","    num_layers=num_layers,\n","    d_model=d_model,\n","    num_heads=num_heads,\n","    d_ff=d_ff,\n","    input_vocab_size=len(input_lang_tokenizer.word_index)+1,\n","    target_vocab_size=len(target_lang_tokenizer.word_index)+1,\n","    pe_input=1000,\n","    pe_target=1000,\n","    rate=dropout_rate)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"f5j3apf6S7K7"},"source":["def create_masks(input, target):\n","\n","    encoder_padding_mask = create_padding_mask(input)\n","\n","    # for encoder output\n","    # in the second block of attention\n","    decoder_padding_mask = create_padding_mask(input)\n","\n","    # for padding and masking future tokens\n","    look_ahead_mask = create_look_ahead_mask(tf.shape(target)[1])\n","    decoder_target_padding_mask = create_padding_mask(target)\n","    \n","    combined_mask = tf.maximum(decoder_target_padding_mask, look_ahead_mask)\n","    return encoder_padding_mask, combined_mask, decoder_padding_mask\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7341YYznS60y"},"source":["\"\"\"\n","# irrelevant-------------------------------------\n","train_step_signature = [\n","                        tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n","                        tf.TensorSpec(shape=(None,None), dtype=tf.int64)\n","]\"\"\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nzc0J0cGS6m5"},"source":["@tf.function#(input_signature=train_step_signature)\n","def train_step(input, target):\n","\n","    target_input = target[:, :-1]\n","    target_real = target[:, 1:]\n","    #print('yes')\n","    encoder_padding_mask,\\\n","    combined_mask, \\\n","    decoder_padding_mask = create_masks(input, target_real)\n","\n","    with tf.GradientTape() as tape:\n","         predictions, _ = transformer(input,\n","                                      target_input,\n","                                      True, \n","                                      encoder_padding_mask,\n","                                      combined_mask,\n","                                      decoder_padding_mask)\n","         \n","         loss = loss_function(target_real, predictions)\n","\n","    gradients = tape.gradient(loss,\n","                              transformer.trainable_variables)\n","    \n","    optimizer.apply_gradients(zip(gradients,\n","                                  transformer.trainable_variables))\n","    \n","    train_loss(loss)\n","    train_accuracy(accuracy_function(target_real, predictions))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nyCkRUbXad5y"},"source":["gc.collect()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"o4d1RtU89xKM"},"source":["epochs = 13\n","\n","# augmented n =10,000\n","# n =1 \n","for epoch in range(epochs):\n","    print(colored(f\"Epoch {epoch+1}\", 'green'))\n","    start = time.time()\n","\n","    train_loss.reset_states()\n","    train_accuracy.reset_states()\n","\n","\n","    for (batch, (input, target)) in enumerate(train_batches):\n","        train_step(input, target)\n","\n","        if batch % 50 == 0:\n","            print(colored(f'Batch {batch}', 'blue'))\n","            print(f\"Loss {train_loss.result():.4f}\\nAccuracy {train_accuracy.result():.4f}\")\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ylu7T-74XBDF"},"source":["# Evaluation"]},{"cell_type":"code","metadata":{"id":"nD54xoINjn4m"},"source":["#tf.compat.v1.disable_eager_execution()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eOXOt314S6QT"},"source":["def evaluate(sent, max_len=40):\n","\n","    # preprocessing every sentence before giving\n","    # them to the model\n","    sentence = process_sents(sent)\n","\n","    # input tokenizer\n","    inputs = [input_lang_tokenizer.word_index[i] for i in sentence.split(' ')]\n","    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n","                                                          maxlen=max_len_input,\n","                                                          padding='post')\n","    inputs = tf.convert_to_tensor(inputs, dtype=tf.int32)\n","\n","\n","    output = tf.expand_dims([target_lang_tokenizer.word_index['<start>']],\n","                            0)\n","    #print('yesyes')\n","    for i in range(max_len):\n","        #print('yeaaaa')\n","        encoder_padding_mask, combined_mask, decoder_padding_mask=\\\n","        create_masks(inputs, output)\n","        #print('yeaaaaaaaa')\n","        # shape pred : (batch_s, seq_tar_len, vocab size)\n","\n","        predictions, attention_ws = transformer(inputs,\n","                                            output,\n","                                            False,\n","                                            encoder_padding_mask,\n","                                            combined_mask,\n","                                            decoder_padding_mask)\n","        # shape pred we want: last token\n","        # (batch_s, 1, vocab)\n","        #print('aha')\n","        predictions = predictions[:, -1:, :]\n","\n","        predicted_id = tf.argmax(predictions,\n","                                 axis=-1, \n","                                 output_type=tf.int32)\n","        #print('aha again')\n","        output = tf.concat([output, predicted_id], \n","                           axis=-1)\n","\n","        #print('it has been concatenated')\n","        if predicted_id == target_lang_tokenizer.word_index['<end>']:\n","            #print('broken')\n","            break\n","\n","        \n","    output_txt = ''\n","    for i in output[0].numpy():\n","        #print('in the for loop')\n","        #print(i)\n","        #print(target_lang_tokenizer.index_word[i])\n","        output_txt = output_txt + target_lang_tokenizer.index_word[i] + ' '\n","\n","    return output_txt, output_txt.split(' '), attention_ws\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VUw2-iOXS6N9"},"source":["def print_poetry(sent):\n","\n","    poetry, tokens, att_weights = evaluate(sent)\n","    print(colored('Text: ', 'green'), sent)\n","    print(colored('Poetry: ', 'green'), poetry)\n","    "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Hfu5H4eb5N_y"},"source":["print_poetry('با این توصیف عشاق بی عقل و بدون هدف خاص زندگی می کنند و دارای هیچ هدف و مغزی نیستند تا اینکه به جهنم می رسند و به هیچ جایگاه دنیوی و واقعی دست پیدا نمی کنند')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kHdTwmJES6Lk"},"source":["print_poetry('با این توصیف عشاق بی عقل و بدون هدف خاص زندگی می کنند و دارای هیچ هدف و مغزی نیستند تا اینکه به جهنم می رسند و به هیچ جایگاه دنیوی و واقعی دست پیدا نمی کنند') # 10"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YSbgIu9C5R36"},"source":["print_poetry('چه خوش است دردی که یار را برای عیادت بر سر بالینم آور')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OY6NhjVv45RE"},"source":["print_poetry('چه خوش است دردی که یار را برای عیادت بر سر بالینم آور')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"b8d3S8S745Ll"},"source":["print_poetry('تحمل مشکلات و سختی ها در این دنیا شما را به مقام والا و عشق و هدف حقیقی در پیش معشوق می رساند.') # 12 ایپاک "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uZURCI_j45Jb"},"source":["print_poetry('تحمل مشکلات و سختی ها در این دنیا شما را به مقام والا و عشق حقیقی در پیش معشوق می رساند.') # 12 ایپاک "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iYRX5nIqE7Nn"},"source":["print_poetry('چه خوش است دردی که یار را برای عیادت بر سر بالینم آور')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dmWXCxDd35Mk"},"source":["print_poetry('ای مردم اینک دور دور عیسی است اسرار دین او را با دل و جان گوش دهید.')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mQ6wZc9n35Ka"},"source":["print_poetry('با این توصیف عشاق بی عقل و بدون هدف خاص زندگی می کنند و دارای هیچ هدف و مغزی نیستند تا اینکه به جهنم می رسند و به هیچ جایگاه دنیوی و واقعی دست پیدا نمی کنند')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IeGffW0VcmFJ"},"source":["# Evaluate and output a dataset"]},{"cell_type":"code","metadata":{"id":"7R9KD9HFgMCu"},"source":["len(all_data)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6Ao-przWz3LF"},"source":["def clean(t):\n","    t = re.sub('^ ', '', t)\n","    t = re.sub(' $', '', t)\n","    t = re.sub(r' */ *', ' / ', t)\n","\n","    t = re.sub(r' \\. \\.', '\\.', t)\n","    t = re.sub(' +\\s', ' ', t)\n","\n","    t = re.sub(' \\.$', '\\.', t)\n","    t = re.sub('^ *\\. *', '', t)\n","\n","    t = re.sub('[۱۲۳۴۵۶۷۸۹۰]', '', t)\n","    \n","    return t"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"A0mNFRyxz0am"},"source":["all_data.loc[:, 'poetry'] = all_data.loc[:, 'poetry'].apply(lambda x: clean(x))\n","all_data.loc[:, 'text'] = all_data.loc[:, 'text'].apply(lambda x: clean(x))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Pgsmd8aa391M"},"source":["print(all_data.loc[0, 'poetry'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uG0X_r8l35H-"},"source":["all_data.loc[input_tensor_val.index]#.isna().sum()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"j7g2BZw9S6Gh"},"source":["def evaluate_dataset(df, max_len=40):\n","\n","    generated_text = []\n","    df = df.reset_index(drop=True)\n","\n","\n","    for r in range(len(df)):\n","\n","        try:\n","            \n","            #print(r)\n","            # preprocessing every sentence before giving\n","            # them to the model\n","            sentence = process_sents(df.loc[r, 'text'])\n","            # input tokenizer\n","            inputs = [input_lang_tokenizer.word_index[i] for i in sentence.split(' ')]\n","            inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n","                                                                maxlen=max_len_input,\n","                                                                padding='post')\n","            # print(inputs)\n","            inputs = tf.convert_to_tensor(inputs, dtype=tf.int32)\n","            # print(inputs)\n","\n","            output = tf.expand_dims([target_lang_tokenizer.word_index['<start>']],\n","                                    0)\n","            #print('yesyes')\n","            for i in range(max_len):\n","                #print('yeaaaa')\n","                encoder_padding_mask, combined_mask, decoder_padding_mask=\\\n","                create_masks(inputs, output)\n","                #print('yeaaaaaaaa')\n","                # shape pred : (batch_s, seq_tar_len, vocab size)\n","\n","                predictions, attention_ws = transformer(inputs,\n","                                                    output,\n","                                                    False,\n","                                                    encoder_padding_mask,\n","                                                    combined_mask,\n","                                                    decoder_padding_mask)\n","                # shape pred we want: last token\n","                # (batch_s, 1, vocab)\n","                #print('aha')\n","                predictions = predictions[:, -1:, :]\n","\n","                predicted_id = tf.argmax(predictions,\n","                                        axis=-1, \n","                                        output_type=tf.int32)\n","                #print('aha again')\n","                output = tf.concat([output, predicted_id], \n","                                axis=-1)\n","\n","                #print('it has been concatenated')\n","                if predicted_id == target_lang_tokenizer.word_index['<end>']:\n","                    #print('broken')\n","                    break\n","\n","                \n","            output_txt = ''\n","            for i in output[0].numpy():\n","                #print('in the for loop')\n","                #print(i)\n","                #print(target_lang_tokenizer.index_word[i])\n","                output_txt = output_txt + target_lang_tokenizer.index_word[i] + ' '\n","\n","            generated_text.append(output_txt)\n","\n","\n","            \n","\n","        except: \n","            print(r)\n","            print(df.loc[r, 'text'])\n","\n","            generated_text.append(None)\n","\n","\n","    df_output = pd.concat([df, pd.Series(generated_text)],\n","                                axis = 1)\n","            \n","    df_output.columns = ['poetry_ground_truth',\n","                        'text',\n","                        'poetry_generated_MHA']\n","                        \n","    return df_output, generated_text\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HzTKkqogS6EB"},"source":["output_df, generated_text = evaluate_dataset(all_data.loc[val_indices][:100], max_len=40)\n","output_df"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VdP55jNvVQDY"},"source":["output_df.to_csv(f'.../Results/MultiHeadAttention_Poetry_19_withAugmented_P&T.csv',\n","                 index=False)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Whh2XoGMhHlP"},"source":["# *Experiment*"]},{"cell_type":"code","metadata":{"id":"2aVK2QA3G0Nn"},"source":["output = output[[len(i)>70 for i in output.text]]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"z_Io6ciYG0Lu"},"source":["output_df[[len(i)>80 for i in output_df.text]]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"D_k7pd8qG0JH"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7jq3wScO8EfB"},"source":["len('توبه باید با اب و محبت همراه باشد')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1YhsoRFb9Dwy"},"source":["all_data.poetry[0]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y9_BfXLJGjGH"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TSJVkSjT8347"},"source":["for i in range(len(output_df)):\n","    if len(output_df.text[i])<50:\n","\n","        print()\n","        print(colored(i, 'blue'))\n","        print(output_df.text[i])\n","        print(colored('generated: ', 'green'), output_df.poetry_generated_MHA[i])\n","        print(colored('gt: ', 'green'), output_df.poetry_ground_truth\t[i])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"H5BDGRJe8GdD"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QbVqSgT92jH9"},"source":["eval_ = all_data.loc[target_tensor_val.index].reset_index(drop=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3WqLVkyQ2jFY"},"source":["print(eval_.loc[32, 'text'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ct9mvSvt2jDK"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qvyK55iQ2jA1"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MTWHk9Sxam5T"},"source":["output_df.to_csv('.../Results/MultiHeadAttention_8_20Epochs_Poetry_17_cleaned_data.csv',\n","                 index=False)\n","\n","# run again"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_KHKXzlIam24"},"source":["for i in range(len(output_df)):\n","    print('\\nground truth: ', output_df.loc[i,'poetry_ground_truth'])\n","    print('generated: ', output_df.loc[i, 'poetry_generated_MHA'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"O0Yx2A0MhBqa"},"source":["output_df, generated_text = evaluate_dataset(all_data.loc[target_tensor_val.index], max_len=40)\n","output_df"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aI9BxqoLS6Bc"},"source":["for record in all_data.loc[target_tensor_val.index].iterrows():\n","    print(record[0])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"q1k-oKT9S5-9"},"source":["output_df.columns = ['poetry_generated_MHA', # modified this\n","                    'text',\n","                    'poetry_generated']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7QQeRyCtS58m"},"source":["output_df.to_csv('.../Results/MultiHeadAttention.csv',\n","                 index=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xsFPNh96S55_"},"source":["output_df.to_csv('.../Results/MultiHeadAttention_Poetry_17.csv',\n","                 index=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HBa0CJW8S53L"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4UGqB7L6S5yZ"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1XVzDexvS5we"},"source":["sentences = []\n","\n","for i in input_tensor_val:\n","    output = ''\n","    for j in i:\n","        if j ==0:\n","            break\n","\n","        output = output + input_lang_tokenizer.index_word[j] + ' '\n","\n","    sentences.append(output)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"stLmKogfS5uT"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aM_nOwTzS5r6"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"D8P7lm2IS5pi"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vsFXciyCWHon"},"source":[""],"execution_count":null,"outputs":[]}]}