{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Pretrainig bert--0.15--onVerse.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"fPeuh14MO3yj"},"source":["! pip install datasets transformers"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0HrioHhGPiqJ"},"source":["from datasets import load_dataset\n","\n","import glob\n","import pickle\n","import re \n","from termcolor import colored\n","from transformers import AutoModelForMaskedLM, AutoTokenizer\n","from transformers import AutoTokenizer\n","from transformers import DataCollatorForLanguageModeling\n","from transformers import Trainer, TrainingArguments\n","import torch\n","import math\n","\n","\n","from sklearn.model_selection import train_test_split\n","import pandas as pd\n","import numpy as np"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IZbblmDePioA"},"source":["# import the data-----------------------------------------------------\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FQbObOBquXEE"},"source":["## 0.2 val & 3 epochs "]},{"cell_type":"code","metadata":{"id":"pxQFuktHFaZb"},"source":["val_path = '.../Data/all_poetry_train_verse.csv'\n","train_path = '.../Data/all_poetry_val_verse.csv'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2yEangO7PikA"},"source":["dataset_poetry = load_dataset('csv', data_files={'train': train_path,\n","                                                'test': val_path})"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SaxNe4KhPih5"},"source":["model_checkpoint = 'HooshvareLab/bert-fa-zwnj-base'\n","    \n","tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, \n","                                          use_fast=True)\n","\n","model = AutoModelForMaskedLM.from_pretrained(model_checkpoint)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DsO3ioZpBYgd"},"source":["model_checkpoint = 'HooshvareLab/bert-fa-zwnj-base'\n","#After training\n","ModelPath = '.../Pretrained Models/Pretrained on verses/BERT_0.15_Verse/BERT_model_all_poems.hpt'\n","model = AutoModelForMaskedLM.from_pretrained(model_checkpoint)\n","model.load_state_dict(torch.load(ModelPath, map_location='cuda'))\n","tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tormnKU_PiK7"},"source":["training_args = TrainingArguments( \n","    \"test-clm\",\n","    evaluation_strategy = \"epoch\",\n","    learning_rate=2e-5,\n","    weight_decay=0.01, \n","    load_best_model_at_end=True\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oCsJnppKQRmT"},"source":["def tokenize_function(examples):\n","    return tokenizer(examples['poetry'])\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dHK7vHefQTIM"},"source":["tokenized_datasets = dataset_poetry.map(\n","    tokenize_function, \n","    batched=True, \n","    num_proc=4,\n","    batch_size=512)\n","\n","\n","tokenized_datasets[\"train\"][1]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GoDy9Ci3QU5R"},"source":["tokenized_datasets"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-obWOIRSQWyD"},"source":["data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer,\n","                                                mlm_probability=0.15)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rhjqzJxQQcjL"},"source":["trainer = Trainer(\n","    model=model, \n","    args=training_args,\n","    train_dataset=tokenized_datasets[\"train\"],\n","    eval_dataset=tokenized_datasets[\"test\"],\n","    data_collator=data_collator, \n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HeNi-wSgQchN"},"source":["trainer.train()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oOhBl4-TQceu"},"source":["eval_results = trainer.evaluate()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UfHNOEy1QccZ"},"source":["ModelPath = '.../BERT_model_all_poems.hpt'\n","torch.save(model.state_dict(), ModelPath)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2Oz6slLgy9rs"},"source":["import math\n","print(f\"Perplexity: {math.exp(eval_results['eval_loss']):.2f}\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OAtkcLsFuJex"},"source":["# 0.1 val & 5 epochs\n"]},{"cell_type":"code","metadata":{"id":"Fs5tHhjIuJXC"},"source":["val_path = '.../Data/all_poetry_train_verse_10p_Val.csv'\n","train_path = '.../Data/all_poetry_val_verse_90p_Train.csv'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"odny7m4auJVK"},"source":["dataset_poetry = load_dataset('csv', data_files={'train': train_path,\n","                                                'test': val_path})"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nmQdQmnBvgtK"},"source":["training_args = TrainingArguments( \n","    \"test-clm\",\n","    evaluation_strategy = \"epoch\",\n","    learning_rate=2e-5,\n","    weight_decay=0.01,  \n","    load_best_model_at_end=True,\n","    num_train_epochs=5\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_Cp42x-yHz9l"},"source":["def tokenize_function(examples):\n","    return tokenizer(examples['poetry'])\n","\n","\n","tokenized_datasets = dataset_poetry.map(\n","    tokenize_function, \n","    batched=True, \n","    num_proc=4,\n","    batch_size=128)\n","\n","\n","tokenized_datasets[\"train\"][1]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UwLy1C1xIrsU"},"source":["data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer,\n","                                                mlm_probability=0.15)\n","\n","trainer = Trainer(\n","    model=model, \n","    args=training_args,\n","    train_dataset=tokenized_datasets[\"train\"],\n","    eval_dataset=tokenized_datasets[\"test\"],\n","    data_collator=data_collator, \n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aiQupUGuuJRC"},"source":["trainer.train()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q4KOkr4DuJO8"},"source":["tokenizer.save_pretrained('.../Pretrained Models/Pretrained on verses/BERT_0.15_Verse_5epochs/')\n","model.save_pretrained('.../Pretrained Models/Pretrained on verses/BERT_0.15_Verse_5epochs/')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YI2LZ0DguJM9"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HQwZTE0fuJK6"},"source":["eval_results = trainer.evaluate()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sPy4GgBi7mRf"},"source":["eval_results"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DAURHr7zuJIa"},"source":["import math\n","print(f\"Perplexity: {math.exp(eval_results['eval_loss']):.2f}\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ggxLugN5uJGS"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"F3ROeLIrQcUr"},"source":[""],"execution_count":null,"outputs":[]}]}